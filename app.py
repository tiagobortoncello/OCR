import streamlit as st
from PIL import Image, ImageEnhance, ImageFilter
import easyocr
import requests
from io import BytesIO
import fitz  # PyMuPDF

# Configura√ß√µes
MODEL_NAME = "Qwen/Qwen2-0.5B-Instruct"
HF_TOKEN = st.secrets.get("HF_API_TOKEN", "")

if not HF_TOKEN:
    st.error("‚ùå Chave de API do Hugging Face n√£o configurada. Adicione 'HF_API_TOKEN' nos Secrets do Streamlit Cloud.")
    st.stop()

@st.cache_resource
def load_ocr():
    # Carrega EasyOCR com suporte a portugu√™s (e ingl√™s, √∫til em textos antigos)
    return easyocr.Reader(['pt', 'en'], gpu=False)

def query_qwen(prompt):
    API_URL = f"https://api-inference.huggingface.co/models/{MODEL_NAME}"
    headers = {"Authorization": f"Bearer {HF_TOKEN}"}
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 512,
            "temperature": 0.6,
            "return_full_text": False,
            "do_sample": True
        }
    }
    response = requests.post(API_URL, headers=headers, json=payload)
    if response.status_code == 200:
        return response.json()[0]["generated_text"]
    else:
        st.error(f"Erro na API: {response.status_code} ‚Äì {response.text}")
        return None

def preprocess_image_for_ocr(pil_image):
    """Melhora a imagem para OCR: escala de cinza, contraste, binariza√ß√£o."""
    if pil_image.mode != 'RGB':
        pil_image = pil_image.convert('RGB')
    gray = pil_image.convert('L')
    enhancer = ImageEnhance.Contrast(gray)
    contrasted = enhancer.enhance(2.0)
    # Binariza√ß√£o com limiar ajustado para textos antigos
    threshold = 140
    bw = contrasted.point(lambda x: 0 if x < threshold else 255, '1')
    # Redu√ß√£o leve de ru√≠do
    bw = bw.filter(ImageFilter.MedianFilter(size=3))
    return bw

def extract_text_from_image_pil(pil_image):
    """Extrai texto de imagem com pr√©-processamento + EasyOCR."""
    processed = preprocess_image_for_ocr(pil_image)
    img_bytes = BytesIO()
    processed.save(img_bytes, format='PNG')
    reader = load_ocr()
    results = reader.readtext(
        img_bytes.getvalue(),
        detail=0,
        paragraph=True,
        min_size=10,
        contrast_ths=0.1,
        adjust_contrast=0.7
    )
    return " ".join(results)

def extract_text_from_scanned_pdf(pdf_bytes):
    """Converte PDF escaneado em imagens e aplica OCR com pr√©-processamento."""
    try:
        pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
        full_text = []
        for page_num in range(pdf_document.page_count):
            page = pdf_document.load_page(page_num)
            mat = fitz.Matrix(2.0, 2.0)  # Aumenta resolu√ß√£o para melhor OCR
            pix = page.get_pixmap(matrix=mat, dpi=200)
            img_data = pix.tobytes("png")
            pil_img = Image.open(BytesIO(img_data))
            with st.spinner(f"üîç Processando p√°gina {page_num + 1}..."):
                text = extract_text_from_image_pil(pil_img)
                if text.strip():
                    full_text.append(f"[P√°gina {page_num + 1}]\n{text}")
        pdf_document.close()
        return "\n\n".join(full_text)
    except Exception as e:
        st.error(f"Erro ao processar PDF escaneado: {str(e)}")
        return ""

# Interface do app
st.set_page_config(page_title="OCR para Documentos Antigos + Qwen", layout="centered")
st.title("üìú OCR para Jornais Antigos & PDFs Escaneados")
st.write("""
Envie **imagens (PNG/JPG)** ou **PDFs escaneados** (ex: jornais, livros antigos, documentos manuscritos).  
O app usa pr√©-processamento avan√ßado para melhorar a leitura de textos antigos.
""")

uploaded = st.file_uploader(
    "Escolha um arquivo",
    type=["png", "jpg", "jpeg", "pdf"]
)

if uploaded:
    file_type = uploaded.type
    extracted_text = ""

    if file_type == "application/pdf":
        st.info("üìÑ Processando PDF escaneado... (pode demorar um pouco)")
        pdf_bytes = uploaded.read()
        extracted_text = extract_text_from_scanned_pdf(pdf_bytes)
    else:
        image = Image.open(uploaded)
        st.image(image, caption="Imagem carregada", use_column_width=True)
        with st.spinner("üîç Extraindo texto com OCR melhorado..."):
            extracted_text = extract_text_from_image_pil(image)

    if extracted_text.strip():
        st.subheader("Texto extra√≠do:")
        st.text_area("Texto OCR", extracted_text, height=250)

        instruction = st.text_input(
            "O que voc√™ quer que o Qwen fa√ßa com esse texto?",
            "Corrija erros de OCR e reescreva o texto de forma clara e leg√≠vel."
        )

        if st.button("Enviar para o Qwen"):
            full_prompt = f"{instruction}\n\nTexto com poss√≠veis erros de OCR:\n{extracted_text}"
            with st.spinner("üß† Processando com Qwen-0.5B..."):
                resposta = query_qwen(full_prompt)
                if resposta:
                    st.subheader("Resposta do Qwen:")
                    st.write(resposta)
    else:
        st.warning("‚ö†Ô∏è Nenhum texto foi encontrado. Tente com uma imagem mais n√≠tida ou com melhor contraste.")
